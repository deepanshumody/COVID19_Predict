# COVID19_Prediction from Hematological Parameters
7 ML Algorithms applied to 7 different datasets to predict covid-19.
We have used SVM, KNN XGBoost, Random Forest, Naive Bayes, Fischer's linear discriminant and Logistic regression.
We have tried different imputation strategies on the dataset to try and come up with best precision and recall scores.

Dataset-1
1)	Logistic regression
•	AUC score:0.83
•	Accuracy:0.70
•	Sensitivity:0.12
•	Specificity:0.97
2)	Naïve Baiye’s
•	AUC score:0.64
•	Accuracy:0.44
•	Sensitivity:0.97
•	Specificity:0.21
3)	Fisher’s linear discriminant:
•	AUC score:0.82
•	Accuracy:0.72
•	Sensitivity:0.95
•	Specificity: 0.18
4)	KNN:
•	AUC score:0.68
•	Accuracy:0.67
•	Sensitivity:0.76
•	Specificity: 0.46
5)	XGBoost
•	AUC score:0.95
•	Accuracy:0.93
•	Sensitivity:0.80
•	Specificity: 0.97

6)	Random Forest
•	AUC score:0.78
•	Accuracy:0.70
•	Sensitivity:0.70
•	Specificity: 0.71
7)	SVM
•	AUC score:0.76
•	Accuracy:0.68
•	Sensitivity:0.06
•	Specificity: 0.97

![image](https://user-images.githubusercontent.com/39831386/130591811-cfa621f3-8f6f-42ff-8a9d-280a30c194f9.png)

Dataset-1b

8)	Logistic regression
•	AUC score: 0.88 
•	Accuracy: 0.90
•	Sensitivity: 0.42
•	Specificity: 0.99
9)	Naïve Baiye’s
•	AUC score: 0.79
•	Accuracy: 0.84
•	Sensitivity: 0.67
•	Specificity: 0.86
10)	Fisher’s linear discriminant:
•	AUC score: 0.89
•	Accuracy: 0.88
•	Sensitivity: 0.42
•	Specificity: 0.96
11)	KNN:
•	AUC score: 0.88
•	Accuracy: 0.91
•	Sensitivity: 0.29
•	Specificity: 1
12)	XGBoost
•	AUC score: 0.96
•	Accuracy: 0.91
•	Sensitivity: 0.87
•	Specificity: 0.92

13)	Random Forest
•	AUC score: 0.91
•	Accuracy: 0.90
•	Sensitivity: 0.29
•	Specificity: 0.98
14)	SVM
•	AUC score: 0.90
•	Accuracy: 0.95
•	Sensitivity: 0.86
•	Specificity: 0.96

![image](https://user-images.githubusercontent.com/39831386/130591843-61ce2cfd-82fc-46bc-9a71-892466a0988e.png)

Dataset-2

15)	Logistic regression
•	AUC score:0.82
•	Accuracy:0.87
•	Sensitivity:0.42
•	Specificity:0.95
16)	Naïve Baiye’s
•	AUC score:0.76
•	Accuracy:0.78
•	Sensitivity:0.58
•	Specificity:0.81

17)	Fisher’s linear discriminant:
•	AUC score:0.83
•	Accuracy:0.86
•	Sensitivity:0.25
•	Specificity: 0.96
18)	KNN:
•	AUC score:0.84
•	Accuracy:0.82
•	Sensitivity:0.29
•	Specificity: 0.89
19)	XGBoost
•	AUC score:0.93
•	Accuracy:0.90
•	Sensitivity:0.71
•	Specificity: 0.94

20)	Random Forest
•	AUC score:0.94
•	Accuracy:0.95
•	Sensitivity:0.75
•	Specificity: 0.92
21)	SVM
•	AUC score:0.77
•	Accuracy:0.88
•	Sensitivity:0
•	Specificity: 1

![image](https://user-images.githubusercontent.com/39831386/130591867-55f12596-bf3a-4c4b-9624-86aaf2b6cf25.png)

Dataset-3

22)	Logistic regression
•	AUC score:0.82
•	Accuracy:0.88
•	Sensitivity:0.25
•	Specificity:0.99
23)	Naïve Baiye’s
•	AUC score:0.78
•	Accuracy:0.79
•	Sensitivity:0.58
•	Specificity:0.82

24)	Fisher’s linear discriminant:
•	AUC score:0.86
•	Accuracy:0.87
•	Sensitivity:0.08
•	Specificity: 1.00

25)	KNN:
•	AUC score:0.77
•	Accuracy:0.90
•	Sensitivity:0.43
•	Specificity: 0.96
26)	XGBoost
•	AUC score:0.94
•	Accuracy:0.91
•	Sensitivity:1
•	Specificity: 0.9

27)	Random Forest
•	AUC score:0.89
•	Accuracy:0.88
•	Sensitivity:0.43
•	Specificity: 0.94
28)	SVM
•	AUC score:0.57
•	Accuracy:0.88
•	Sensitivity:0.00
•	Specificity: 1.00

![image](https://user-images.githubusercontent.com/39831386/130591883-06c097f0-501f-4d22-ba19-433000597efb.png)

Dataset-4

29)	Logistic regression
•	AUC score: 0.85
•	Accuracy:0.78
•	Sensitivity:0.82
•	Specificity:0.74
30)	Naïve Baiye’s
•	AUC score:0.82
•	Accuracy:0.69
•	Sensitivity:0.92
•	Specificity:0.43

31)	Fisher’s linear discriminant:
•	AUC score:0.87
•	Accuracy:0.81
•	Sensitivity:0.86
•	Specificity: 0.76

32)	KNN:
•	AUC score:0.82
•	Accuracy:0.71
•	Sensitivity:0.78
•	Specificity: 0.64
33)	XGBoost
•	AUC score:0.84
•	Accuracy:0.78
•	Sensitivity:0.76
•	Specificity: 0.81

34)	Random Forest
•	AUC score:0.86
•	Accuracy:0.76
•	Sensitivity:0.71
•	Specificity: 0.83
35)	SVM
•	AUC score:0.83
•	Accuracy:0.77
•	Sensitivity:0.77
•	Specificity: 0.78

![image](https://user-images.githubusercontent.com/39831386/130591904-a6e5c357-24e3-4aa2-86c6-f3afc2092d68.png)

Dataset-5

36)	Logistic regression
•	AUC score:0.77
•	Accuracy:0.69
•	Sensitivity:0.83
•	Specificity:0.52
37)	Naïve Baiye’s
•	AUC score:0.73
•	Accuracy:0.66
•	Sensitivity:0.91
•	Specificity:0.38

38)	Fisher’s linear discriminant:
•	AUC score:0.77
•	Accuracy:0.69
•	Sensitivity:0.87
•	Specificity: 0.50
39)	KNN:
•	AUC score:0.73
•	Accuracy:0.69
•	Sensitivity:0.71
•	Specificity: 0.67
40)	XGBoost
•	AUC score:0.79
•	Accuracy:0.74
•	Sensitivity:0.78
•	Specificity: 0.68

41)	Random Forest
•	AUC score:0.73
•	Accuracy:0.68
•	Sensitivity:0.62
•	Specificity: 0.74
42)	SVM
•	AUC score:0.70
•	Accuracy:0.63
•	Sensitivity:0.81
•	Specificity: 0.46

![image](https://user-images.githubusercontent.com/39831386/130591924-4baeb83c-89fa-4509-abbf-1d6639282144.png)

Dataset-6

43)	Logistic regression
•	AUC score:0.77
•	Accuracy:0.78
•	Sensitivity:0.47
•	Specificity:0.90
44)	Naïve Baiye’s
•	AUC score:0.72
•	Accuracy:0.70
•	Sensitivity:0.67
•	Specificity:0.72

45)	Fisher’s linear discriminant:
•	AUC score:0.75
•	Accuracy:0.75
•	Sensitivity: 0.23
•	Specificity: 0.95
46)	KNN:
•	AUC score:0.8
•	Accuracy:0.76
•	Sensitivity:0.53
•	Specificity: 0.86
47)	XGBoost
•	AUC score:0.84
•	Accuracy:0.76
•	Sensitivity:0.76
•	Specificity: 0.76

48)	Random Forest
•	AUC score:0.83
•	Accuracy:0.78
•	Sensitivity:0.52
•	Specificity: 0.90
49)	SVM
•	AUC score:0.79
•	Accuracy:0.74
•	Sensitivity:0.24
•	Specificity: 0.96

![image](https://user-images.githubusercontent.com/39831386/130591946-bc979a76-565b-4bad-aa04-b7846b4122e2.png)
